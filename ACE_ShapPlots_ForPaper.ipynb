{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add subgroup analysis - DHL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T08:25:57.064756Z",
     "start_time": "2022-09-28T08:25:56.760332Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import tempfile\n",
    "from pickle import dump, load\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from ace_ai_shap_multioutput_v7_addplot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T09:09:53.709904Z",
     "start_time": "2022-09-28T09:09:53.703959Z"
    }
   },
   "outputs": [],
   "source": [
    "# input file\n",
    "train_file = 'data/DP_Phase4_combined_v3_train.csv'\n",
    "test_file = 'data/DP_Phase4_combined_v3_test.csv'\n",
    "\n",
    "# Model files\n",
    "model_name = '3m'\n",
    "features_file = 'saved_model/featurelist_{}.csv'.format(model_name)\n",
    "scaler_file = 'saved_model/scaler_{}.pkl'.format(model_name)\n",
    "model_file = 'saved_model/phase4_{}_model'.format(model_name)\n",
    "kmeans_file = 'saved_model/kmeans_{}.pkl'.format(model_name)\n",
    "featdict_file = 'saved_model/features_dict_{}.pkl'.format(model_name)\n",
    "exclusion_file = 'Intermediate_tables/ACE_Final_Model_ExclusionFeatures.xlsx'\n",
    "target_file = 'Intermediate_tables/ACE_Target_Map.csv'\n",
    "map_file = 'Intermediate_tables/ACE_Feature_Map.csv'\n",
    "\n",
    "target_col = [\n",
    "    'Cerebral_Vascular_Accident', 'Diabetes_Mellitus',\n",
    "    'Dyslipidaemia', 'Heart_and_Circulatory', 'Hypertension',\n",
    "    'Osteoporosis', 'Renal_Disease', 'Osteoarthritis', 'Deceased'\n",
    "]\n",
    "\n",
    "prior_diag_col = [\"Cerebral_Vascular_Accident_Diagnosed\",\"Cerebral_Vascular_Accident_Medication\",\n",
    "                  \"Cerebral_Vascular_Accident_Test\",\"Diabetes_Mellitus_Diagnosed\",\"Diabetes_Mellitus_Medication\",\n",
    "                  \"Diabetes_Mellitus_Test\",\"Dyslipidaemia_Diagnosed\",\"Dyslipidaemia_Medication\",\"Dyslipidaemia_Test\",\n",
    "                  \"Heart_and_Circulatory_Diagnosed\",\"Heart_and_Circulatory_Medication\",\"Heart_and_Circulatory_Test\",\n",
    "                  \"Hypertension_Diagnosed\",\"Hypertension_Medication\",\"Hypertension_Test\",\"Osteoporosis_Diagnosed\",\n",
    "                  \"Osteoporosis_Medication\",\"Osteoporosis_Test\",\"Osteoarthritis_Diagnosed\",\"Osteoarthritis_Medication\",\n",
    "                  \"Osteoarthritis_Test\",\"Renal_Disease_Diagnosed\",\"Renal_Disease_Medication\",\"Renal_Disease_Test\",\n",
    "                  \"Deceased_Diagnosed\",\"Deceased_Medication\",\"Deceased_Test\"\n",
    "]\n",
    "\n",
    "prior_diag_drop = [\"Cerebral_Vascular_Accident_Test\", \"Cerebral_Vascular_Accident_Medication\",\n",
    "                  \"Heart_and_Circulatory_Medication\", \"Heart_and_Circulatory_Test\",\n",
    "                  \"Hypertension_Test\",\n",
    "                  \"Osteoporosis_Test\",\n",
    "                  \"Osteoarthritis_Medication\", \"Osteoarthritis_Test\",\n",
    "                  \"Renal_Disease_Medication\",\n",
    "                  \"Deceased_Diagnosed\",\"Deceased_Medication\",\"Deceased_Test\"\n",
    "]\n",
    "\n",
    "target_prior_col = [target+'_Prior' for target in target_col[:-1]]\n",
    "\n",
    "# SHAP parameters\n",
    "non_periodic_features = ['PAT_AGE', 'GENDER_Male', 'GENDER_Female', \n",
    "                         'RACE_Chinese', 'RACE_Malay', 'RACE_Indian', 'RACE_Others',\n",
    "                         \"Cancer_Prior\",\"Cerebral_Vascular_Accident_Prior\",\"Diabetes_Mellitus_Prior\",\n",
    "                         \"Dyslipidaemia_Prior\",\"Heart_and_Circulatory_Prior\",\"Hypertension_Prior\",\n",
    "                         \"Osteoporosis_Prior\",\"Renal_Disease_Prior\",\"OverWeight_Prior\",\n",
    "                         \"Osteoarthritis_Prior\",\"BPH_Prior\",\"COPD_Prior\",\"Epilepsy_Prior\",\"HepB_Prior\",\n",
    "                         \"Parkinson_Prior\",\"Psoriasis_Prior\",\"RA_Prior\",\"Allergic_Prior\",\"Asthma_Prior\",\n",
    "                         \"Dementia_Prior\",\"Gout_Prior\"\n",
    "] + prior_diag_col\n",
    "\n",
    "# features to drop\n",
    "feature_to_drop = ['PAT_ID'] + target_col + target_prior_col + prior_diag_drop\n",
    "\n",
    "# validation data size\n",
    "val_size=1000\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "feature_periods = ['YEARH_', 'YEAR1_', 'YEAR1H_', 'YEAR2_', 'YEAR2H_', 'YEAR3_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files\n",
    "feature_names = pd.read_csv(features_file)['Feature name'].tolist()\n",
    "train = pd.read_csv(train_file, usecols=feature_to_drop+feature_names)\n",
    "\n",
    "# test = pd.read_csv(test_file, usecols=feature_to_drop+feature_names)\n",
    "# train = pd.concat([train, test], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define process function, combine scaler\n",
    "def data_proc_X(data, feature_names, scaler_file=None):\n",
    "    X = data[feature_names]\n",
    "    X.fillna(-1, inplace=True)  # Fill in missing with -1\n",
    "    X = np.asarray(X)  # Convert to array\n",
    "    \n",
    "    if scaler_file is None:\n",
    "        X = X\n",
    "    else:\n",
    "        scaler = load(open(scaler_file, 'rb'))  # Load scaler\n",
    "        X = scaler.transform(X)  # Scale data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to unpickle estimator MinMaxScaler from version 0.24.2 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(model_file, compile=False)\n",
    "scaler = load(open(scaler_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_3m\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 275)]             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1024)              282624    \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 9)                 4617      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 812,041\n",
      "Trainable params: 812,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kmeans = load(open(kmeans_file, 'rb'))\n",
    "features_dict = load(open(featdict_file, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction using processed data\n",
    "def only_predict(model, test_features_scaled, data, BATCH_SIZE):\n",
    "    start_time = datetime.now()\n",
    "    test_predictions = model.predict(test_features_scaled, batch_size=BATCH_SIZE)\n",
    "    print(test_predictions.shape)\n",
    "    end_time = datetime.now()\n",
    "    print(\"predictions took \", end_time - start_time)\n",
    "    \n",
    "    # [BW]: use original input values, not processed ones\n",
    "    # Create data frame with feature values and predictions for all patients\n",
    "    test_df = data.copy() \n",
    "    test_df['Deceased_Prior'] = 0\n",
    "    \n",
    "    # get prediction probabilities: rescale\n",
    "    for i, target in enumerate(target_col):\n",
    "        test_df[target + '_Proba'] = test_predictions[:,i]\n",
    "        \n",
    "    return test_df\n",
    "\n",
    "\n",
    "# Prediction starting from data processing\n",
    "def make_predict(model, data, feature_names, scaler_file):\n",
    "    # Process data\n",
    "    test_features_scaled = data_proc_X(data, feature_names, scaler_file)\n",
    "    print('Test features shape:', test_features_scaled.shape)\n",
    "    \n",
    "    # Predict \n",
    "    test_df = only_predict(model, test_features_scaled, data, BATCH_SIZE)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"PAT_ID\"].isin(selected_pats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = make_predict(model, train, feature_names, scaler_file)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, pat in enumerate(selected_pats):\n",
    "    print(f\"Patient: {pat}\")\n",
    "    print(f\"pat number: {i+1}\")\n",
    "    df = train[train['PAT_ID']==pat].reset_index()\n",
    "    \n",
    "    # Instantiate the DeepPatientShap class --> Only need to instantiate once\n",
    "    shap_explain = DeepPatientShap(\n",
    "        scaler=scaler,\n",
    "        model=model,\n",
    "        X_train_kmeans=train_kmeans,  # summarized dataset\n",
    "        X_test=data_proc_X(df, feature_names),  # dataset to generate feature importance for (ie production data)\n",
    "        features=feature_names,\n",
    "        targets=target_col,\n",
    "        full_targets=target_col,\n",
    "        categorical_features={\n",
    "            'GENDER': ['GENDER_Male', 'GENDER_Female'],\n",
    "            'RACE': ['RACE_Chinese', 'RACE_Malay', 'RACE_Indian', 'RACE_Others'],\n",
    "        },\n",
    "        ex_features=non_periodic_features,\n",
    "        features_dict=features_dict,\n",
    "        )\n",
    "    \n",
    "    for target in [\"Diabetes_Mellitus\", \"Dyslipidaemia\"]:\n",
    "        \n",
    "        fig, shap_df = shap_explain.plot_shap_force(target=target, row_ind=0)\n",
    "        fig.savefig(f\"plots_final/forceplot_{target}_{i+1}.png\", bbox_inches='tight')\n",
    "        shap_df.to_csv(f\"plots_final/forceplot_{target}_{i+1}.csv\", index=False)\n",
    "        \n",
    "        display(shap_df.head())\n",
    "        plt.show()\n",
    "        \n",
    "        print(target, \"saved\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
